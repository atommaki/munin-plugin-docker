#!/usr/bin/env python3

# https://github.com/atommaki/munin-plugin-docker

import docker
import sys
import os
import datetime
import statistics
import re
import subprocess
import json

class munindocker:
    def _convert_to_bytes(self,size_str):
        size_str = size_str.strip().upper()
        size_map = {'B': 1, 'KB': 1000, 'MB': 1000**2, 'GB': 1000**3, 'TB': 1000**4}
        # docker scales with 1000, but munin graphs scale with 1024 :/

        match = re.match(r"(\d+(\.\d+)?)\s*([KMGTP]?B)", size_str)
        if match:
            size_value = float(match.group(1))
            size_unit = match.group(3)
            return int(size_value * size_map[size_unit])
        else:
            return 0  # Return 0 if size is '0B' or not found

    def _get_genieric_config(self):
        return (
            'graph_category Docker\n'
        )

    def get_config_containers(self):
        return (
            self._get_genieric_config() +
            'graph_title Docker containers\n'
            'graph_args -l 0\n'
            'graph_vlabel number of containers\n'
            'all_containers.label all containers\n'
            'running_containers.label running containers'
        )

    def get_config_containers_uptime(self):
        return (
            self._get_genieric_config() +
            'graph_title Docker containers uptime\n'
            'graph_args -l 0\n'
            'graph_vlabel uptime hours\n'
            'uptime_max.label max\n'
            'uptime_min.label min\n'
            'uptime_median.label median'
        )

    def get_config_images(self):
        return (
            self._get_genieric_config() + 
            'graph_title Docker images\n'
            'graph_args -l 0\n'
            'graph_vlabel number of images\n'
            'images.label docker images'
        )

    def get_config_layerssize(self):
        return (
            self._get_genieric_config() + 
            'graph_title Docker LayersSize\n'
            'graph_args -l 0\n'
            'graph_vlabel Byte\n'
            'layerssize.label LayersSize'
        )

    def get_config_volumes_n(self):
        return (
            self._get_genieric_config() + 
            'graph_title Docker Volumes (number)\n'
            'graph_args -l 0\n'
            'graph_vlabel number of volumes\n'
            'volumes_n_all.label all volumes\n'
            'volumes_n_active.label active volumes'
        )

    def get_config_volumes_size(self):
        return (
            self._get_genieric_config() + 
            'graph_title Docker Volumes (size)\n'
            'graph_args -l 0\n'
            'graph_vlabel Byte\n'
            'volumes_size.label summarized local volume size\n'
            'volumes_reclaimable.label reclaimable size'
        )

    def get_config_memory(self):
        return (
            self._get_genieric_config() + 
            'graph_title Docker containers memory usage\n'
            'graph_args -l 0\n'
            'graph_vlabel Byte\n'
            'total.label total\n'
            'avg.label avg\n'
            'max.label max'
        )

    def _get_containers_list(self, all = False):
        client = docker.from_env()
        return client.containers.list(all)

    def get_values_containers(self):
        return (
            f"running_containers.value {len(self._get_containers_list())}\n"
            f"all_containers.value {len(self._get_containers_list(all=True))}"
        )
    def get_values_containers_uptime(self):
        uptime_list = []
        dclient_low = docker.APIClient()
        dtimeformat="%Y-%m-%dT%H:%M:%S"
        for container in self._get_containers_list():
            inspect = dclient_low.inspect_container(container.name)
            if "State" in inspect.keys() and "StartedAt" in inspect["State"].keys():
                uptime_list.append((datetime.datetime.utcnow()-datetime.datetime.strptime(inspect["State"]["StartedAt"].split('.')[0],'%Y-%m-%dT%H:%M:%S')).total_seconds()/3600)
        if len(uptime_list) == 0:
            return None
        return (
            f"uptime_max.value {max(uptime_list)}\n"
            f"uptime_min.value {min(uptime_list)}\n"
            f"uptime_median.value {statistics.median(uptime_list)}\n"
        )

    def get_values_images(self):
        client = docker.from_env()
        return (
            f"images.value {len(client.images.list())}"
        )

    def get_values_layerssize(self):
        client = docker.from_env()
        return (
            f"layerssize.value {client.df()['LayersSize']}"
        )

    def get_values_volumes_n(self):
        result = subprocess.run(['docker', 'system', 'df', '--format', 'json'], stdout=subprocess.PIPE, text=True)
        docker_df_list = json.loads("[" + result.stdout.strip().replace('\n', ',') + "]")
        for docker_df in docker_df_list:
            if docker_df['Type'] != 'Local Volumes':
                continue
            return (
                f"volumes_n_all.value { docker_df['TotalCount'] }\n"
                f"volumes_n_active.value { docker_df['Active'] }"
            )

    def get_values_volumes_size(self):
        result = subprocess.run(['docker', 'system', 'df', '--format', 'json'], stdout=subprocess.PIPE, text=True)
        docker_df_list = json.loads("[" + result.stdout.strip().replace('\n', ',') + "]")
        for docker_df in docker_df_list:
            if docker_df['Type'] != 'Local Volumes':
                continue
            return (
                f"volumes_size.value { self._convert_to_bytes(docker_df['Size']) }\n"
                f"volumes_reclaimable.value  { self._convert_to_bytes(docker_df['Reclaimable']) }"
            )


    def get_values_memory(self):
        memory_usage=[]
        for container in self._get_containers_list():
            # TODO 1: what if the container stopped in the meantime?
            # TODO 2: parallel processing would make it faster, currently one run can take seconds
            memory_usage.append(int(container.stats(stream=False)["memory_stats"]["usage"]))
        if len(memory_usage) == 0:
            return None
        return (
            f"total.value {sum(memory_usage)}\n"
            f"avg.value {sum(memory_usage)/len(memory_usage)}\n"
            f"max.value {max(memory_usage)}\n"
        )

metrics = [ 'containers', 'containers_uptime', 'images', 'memory', 'layerssize', 'volumes_n', 'volumes_size' ]

if os.path.basename(__file__) == 'docker_stat':
    print(f"Make symlinks to this file as:", file=sys.stderr)
    for m in metrics:
        print(f"    docker_stat_{m}", file=sys.stderr)
    sys.exit(1)


metric=os.path.basename(__file__).replace('docker_stat_','')

if metric not in metrics:
    print(f"Unknown docker stat type: {metric}", file=sys.stderr)
    print("Valid types:", file=sys.stderr)
    for m in metrics:
        print(f"    {m}", file=sys.stderr)
    sys.exit(1)

md=munindocker()
get_munin_config=getattr(md, f"get_config_{metric}")
get_munin_values=getattr(md, f"get_values_{metric}")

if len(sys.argv) > 1 and sys.argv[1] == 'config':
    print(get_munin_config())
else:
    values =  get_munin_values()
    if values != None:
        print(values)

